{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinay247-g/BDA_Assignment_02/blob/main/BDA__ASSIGNMENT__02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpwrP3JjQqkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a0d477-4347-4498-d2c7-5c95da3150ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Classification Model with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "B_Hqobclu4fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TweetSentimentClassifier\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "7LVxLfIGAlT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tweet_sentiment dataset"
      ],
      "metadata": {
        "id": "g95QUh-Iu81_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/tweet_sentiment.csv\", header=True, inferSchema=True)\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWMJ6S4JKG2d",
        "outputId": "f4b205b3-1f91-487c-9b6d-32849a743c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|               tweet|sentiment|\n",
            "+--------------------+---------+\n",
            "|The event starts ...|  neutral|\n",
            "|I hate how this t...| negative|\n",
            "|Fantastic experie...| positive|\n",
            "|Fantastic experie...| positive|\n",
            "|This is the worst...| negative|\n",
            "+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower, regexp_replace\n",
        "\n",
        "df_clean = df.withColumn(\"tweet_clean\", lower(col(\"tweet\")))\n",
        "df_clean = df_clean.withColumn(\"tweet_clean\", regexp_replace(\"tweet_clean\", \"http\\\\S+|www\\\\S+\", \"\"))\n",
        "df_clean = df_clean.withColumn(\"tweet_clean\", regexp_replace(\"tweet_clean\", \"[^a-zA-Z\\\\s]\", \"\"))\n",
        "df_clean = df_clean.withColumn(\"tweet_clean\", regexp_replace(\"tweet_clean\", \"\\\\s+\", \" \"))\n",
        "df_clean.select(\"tweet_clean\", \"sentiment\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx7A582QKXBb",
        "outputId": "1f4aecee-6fd7-45ad-fb41-5838801d43ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+---------+\n",
            "|tweet_clean                 |sentiment|\n",
            "+----------------------------+---------+\n",
            "|the event starts at pm      |neutral  |\n",
            "|i hate how this turned out  |negative |\n",
            "|fantastic experience        |positive |\n",
            "|fantastic experience        |positive |\n",
            "|this is the worst thing ever|negative |\n",
            "+----------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"tweet_clean\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "tf = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=5000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "label_indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, tf, idf, label_indexer, lr])\n"
      ],
      "metadata": {
        "id": "NQmMfRZqKgLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df_clean.randomSplit([0.8, 0.2], seed=42)\n",
        "model = pipeline.fit(train_data)\n",
        "predictions = model.transform(test_data)\n"
      ],
      "metadata": {
        "id": "9fPizZNQKmw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "predictions.select(\"tweet\", \"sentiment\", \"prediction\").show(5)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPs2Bbu0KwEU",
        "outputId": "5efb8afd-f3cb-49fe-9eb6-e53bef5d6280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+----------+\n",
            "|               tweet|sentiment|prediction|\n",
            "+--------------------+---------+----------+\n",
            "|Absolutely loved ...| positive|       0.0|\n",
            "|Absolutely loved ...| positive|       0.0|\n",
            "|Absolutely loved ...| positive|       0.0|\n",
            "|Absolutely loved ...| positive|       0.0|\n",
            "|Absolutely loved ...| positive|       0.0|\n",
            "+--------------------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Clustering Model with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "1pnnj1ydvJTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CustomerClustering\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "oX0rchQ4NHtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading customer_segmentation dataset"
      ],
      "metadata": {
        "id": "_UcsWTXevPsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/customer_segmentation.csv\", header=True, inferSchema=True)\n",
        "df.show(5)\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owolmMCNNJ49",
        "outputId": "17693af0-9db4-4015-f733-898a5533f9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+--------------+------+-------+--------+-----------+-------+--------+---------+---------------+---------------+----------------+------------+-----------------+---------------+-------------------+-----------------+-----------------+------------+------------+------------+------------+------------+--------+-------------+---------+--------+\n",
            "|  ID|Year_Birth| Education|Marital_Status|Income|Kidhome|Teenhome|Dt_Customer|Recency|MntWines|MntFruits|MntMeatProducts|MntFishProducts|MntSweetProducts|MntGoldProds|NumDealsPurchases|NumWebPurchases|NumCatalogPurchases|NumStorePurchases|NumWebVisitsMonth|AcceptedCmp3|AcceptedCmp4|AcceptedCmp5|AcceptedCmp1|AcceptedCmp2|Complain|Z_CostContact|Z_Revenue|Response|\n",
            "+----+----------+----------+--------------+------+-------+--------+-----------+-------+--------+---------+---------------+---------------+----------------+------------+-----------------+---------------+-------------------+-----------------+-----------------+------------+------------+------------+------------+------------+--------+-------------+---------+--------+\n",
            "|5524|      1957|Graduation|        Single| 58138|      0|       0| 04-09-2012|     58|     635|       88|            546|            172|              88|          88|                3|              8|                 10|                4|                7|           0|           0|           0|           0|           0|       0|            3|       11|       1|\n",
            "|2174|      1954|Graduation|        Single| 46344|      1|       1| 08-03-2014|     38|      11|        1|              6|              2|               1|           6|                2|              1|                  1|                2|                5|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n",
            "|4141|      1965|Graduation|      Together| 71613|      0|       0| 21-08-2013|     26|     426|       49|            127|            111|              21|          42|                1|              8|                  2|               10|                4|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n",
            "|6182|      1984|Graduation|      Together| 26646|      1|       0| 10-02-2014|     26|      11|        4|             20|             10|               3|           5|                2|              2|                  0|                4|                6|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n",
            "|5324|      1981|       PhD|       Married| 58293|      1|       0| 19-01-2014|     94|     173|       43|            118|             46|              27|          15|                5|              5|                  3|                6|                5|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n",
            "+----+----------+----------+--------------+------+-------+--------+-----------+-------+--------+---------+---------------+---------------+----------------+------------+-----------------+---------------+-------------------+-----------------+-----------------+------------+------------+------------+------------+------------+--------+-------------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Year_Birth: integer (nullable = true)\n",
            " |-- Education: string (nullable = true)\n",
            " |-- Marital_Status: string (nullable = true)\n",
            " |-- Income: integer (nullable = true)\n",
            " |-- Kidhome: integer (nullable = true)\n",
            " |-- Teenhome: integer (nullable = true)\n",
            " |-- Dt_Customer: string (nullable = true)\n",
            " |-- Recency: integer (nullable = true)\n",
            " |-- MntWines: integer (nullable = true)\n",
            " |-- MntFruits: integer (nullable = true)\n",
            " |-- MntMeatProducts: integer (nullable = true)\n",
            " |-- MntFishProducts: integer (nullable = true)\n",
            " |-- MntSweetProducts: integer (nullable = true)\n",
            " |-- MntGoldProds: integer (nullable = true)\n",
            " |-- NumDealsPurchases: integer (nullable = true)\n",
            " |-- NumWebPurchases: integer (nullable = true)\n",
            " |-- NumCatalogPurchases: integer (nullable = true)\n",
            " |-- NumStorePurchases: integer (nullable = true)\n",
            " |-- NumWebVisitsMonth: integer (nullable = true)\n",
            " |-- AcceptedCmp3: integer (nullable = true)\n",
            " |-- AcceptedCmp4: integer (nullable = true)\n",
            " |-- AcceptedCmp5: integer (nullable = true)\n",
            " |-- AcceptedCmp1: integer (nullable = true)\n",
            " |-- AcceptedCmp2: integer (nullable = true)\n",
            " |-- Complain: integer (nullable = true)\n",
            " |-- Z_CostContact: integer (nullable = true)\n",
            " |-- Z_Revenue: integer (nullable = true)\n",
            " |-- Response: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Drop non-numeric columns if any (e.g., customer name/ID)\n",
        "numeric_cols = [field.name for field in df.schema.fields if str(field.dataType) in ['IntegerType', 'DoubleType']]\n",
        "df_numeric = df.select(*numeric_cols)\n",
        "df_numeric = df_numeric.dropna()\n",
        "df_numeric.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As188GMYNZl9",
        "outputId": "95b33ff9-ca21-4660-ae73-8f1a502cac7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++\n",
            "||\n",
            "++\n",
            "||\n",
            "||\n",
            "||\n",
            "||\n",
            "||\n",
            "++\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=df_numeric.columns, outputCol=\"features\")\n",
        "assembled_data = assembler.transform(df_numeric)\n",
        "assembled_data.select(\"features\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y5wPcn1NfT2",
        "outputId": "a26ae70d-b1d8-4b46-e7f9-f203ec6d4e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|features|\n",
            "+--------+\n",
            "|[]      |\n",
            "|[]      |\n",
            "|[]      |\n",
            "|[]      |\n",
            "|[]      |\n",
            "+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "evaluator = ClusteringEvaluator()\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(f\"Silhouette Score: {silhouette:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jyjXyo8OA3_",
        "outputId": "c376bc67-d163-4ff6-b3f2-6910aac1b672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.1440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Recommendation Engine with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "PVWYqBq3vYjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MovieRecommender\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "L9tT2QQ5USyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading movies and ratings dataset"
      ],
      "metadata": {
        "id": "ENBWkYQwvdnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = spark.read.csv(\"/content/movies.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"/content/ratings.csv\", header=True, inferSchema=True)\n",
        "\n",
        "movies.show(3)\n",
        "ratings.show(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UgMpgKgUXTS",
        "outputId": "48aa91fd-5881-4a7b-f6be-274a90f024b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     1|      1|   4.0|964982703|\n",
            "|     1|      3|   4.0|964981247|\n",
            "|     1|      6|   4.0|964982224|\n",
            "+------+-------+------+---------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Drop any NA\n",
        "ratings_clean = ratings.dropna()\n",
        "\n",
        "# Split into train/test\n",
        "(train, test) = ratings_clean.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "bX9oUmo9Uwrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",  # avoids NaN predictions\n",
        "    nonnegative=True,\n",
        "    implicitPrefs=False\n",
        ")\n",
        "\n",
        "model = als.fit(train)\n"
      ],
      "metadata": {
        "id": "26Haw-vqU4cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test)\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error = {rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoyestTxVAn9",
        "outputId": "15023137-cbcd-43ef-8bcf-972ed874494d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error = 0.9363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_recs = model.recommendForAllUsers(5)\n",
        "user_recs.show(3, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS_cY7eWVGRO",
        "outputId": "dc305414-2d37-4df4-d233-64008e7d91d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                                  |\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "|1     |[{53123, 5.6336946}, {1284, 5.591563}, {171, 5.5268326}, {104374, 5.526624}, {142488, 5.5156565}]|\n",
            "|2     |[{86320, 5.21019}, {5181, 4.9875655}, {94959, 4.913584}, {142488, 4.9078627}, {131724, 4.892934}]|\n",
            "|3     |[{56145, 5.327325}, {6835, 4.897882}, {5746, 4.897882}, {5181, 4.8322754}, {4518, 4.7941036}]    |\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 123\n",
        "model.recommendForUserSubset(ratings.filter(ratings.userId == user_id), 5).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAt88EBQVNDl",
        "outputId": "f7a02a2c-9ea2-4b97-f45b-e786dcbd2f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                                  |\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "|123   |[{89904, 4.643761}, {177593, 4.6376953}, {183897, 4.5980153}, {1658, 4.576263}, {3358, 4.574531}]|\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/Dxn1w9ETpgSW6AGe93hF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}